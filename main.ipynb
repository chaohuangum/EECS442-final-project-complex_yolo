{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Entry point for the main training, on 6000 images, batch size of 12, and 1000 epochs. \n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import logging \n",
    "#from logger import Logger\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from complexYOLO import ComplexYOLO\n",
    "from kitti import KittiDataset\n",
    "from region_loss import RegionLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = str(datetime.date.today())\n",
    "logging_file = 'training_log_' + date_str + '.log'\n",
    "logging.basicConfig(filename = logging_file, level=logging.DEBUG, format = '%(asctime)s %(message)s')\n",
    "\n",
    "batch_size = 12\n",
    "\n",
    "# Remove old loggings in the tensorboard folder \n",
    "ts_dir = './logs'\n",
    "for ts_file in os.listdir(ts_dir):\n",
    "  ts_path = os.path.join(ts_dir, ts_file)\n",
    "  os.unlink(ts_path)\n",
    "\n",
    "# dataset\n",
    "dataset=KittiDataset(root = '/home/ubuntu/KITTI', set = 'train')\n",
    "data_loader = data.DataLoader(dataset, batch_size, shuffle = True, pin_memory = False)\n",
    "\n",
    "model = ComplexYOLO()\n",
    "model.cuda()\n",
    "\n",
    "# define optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-5 ,momentum = 0.9 , weight_decay = 0.0005)\n",
    "\n",
    "# define the number of epochs\n",
    "epochs = range(200)\n",
    "\n",
    "# Define the loss function\n",
    "region_loss = RegionLoss(num_classes = 8, num_anchors = 5)\n",
    "num_iters = int(len(data_loader.dataset) / batch_size)\n",
    "#loss_history = np.zeros((len(epochs), num_iters, 8))\n",
    "loss_history = np.zeros((1000, num_iters, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Epoch 0 start\n",
      "-------Iteration 0 loss: 8375.56640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/complex_yolo_3d/region_loss.py:216: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = loss_x + loss_y + loss_w + loss_l + loss_conf + loss_cls + loss_Euler + torch.tensor(loss_iou).cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Iteration 200 loss: 1988.9866943359375\n",
      "-------Iteration 400 loss: 1830.7156982421875\n",
      "-------Iteration 600 loss: 1615.9527587890625\n",
      "=======Eppoch 0 finished, loss:  1934.0467565016606\n",
      "=======Epoch 1 start\n",
      "-------Iteration 0 loss: 1945.0830078125\n",
      "-------Iteration 200 loss: 1689.803955078125\n",
      "-------Iteration 400 loss: 1813.08984375\n",
      "-------Iteration 600 loss: 1908.880615234375\n",
      "=======Eppoch 1 finished, loss:  1899.3046443774267\n",
      "=======Epoch 2 start\n",
      "-------Iteration 0 loss: 1564.8287353515625\n",
      "-------Iteration 200 loss: 2353.2841796875\n",
      "-------Iteration 400 loss: 1173.369140625\n",
      "-------Iteration 600 loss: 1535.560302734375\n",
      "=======Eppoch 2 finished, loss:  1881.4264037119253\n",
      "=======Epoch 3 start\n",
      "-------Iteration 0 loss: 1411.9024658203125\n",
      "-------Iteration 200 loss: 1462.0875244140625\n",
      "-------Iteration 400 loss: 1854.1861572265625\n",
      "-------Iteration 600 loss: 1620.0513916015625\n",
      "=======Eppoch 3 finished, loss:  1891.7634630082696\n",
      "=======Epoch 4 start\n",
      "-------Iteration 0 loss: 1996.6651611328125\n",
      "-------Iteration 200 loss: 1276.2359619140625\n",
      "-------Iteration 400 loss: 1853.1739501953125\n",
      "-------Iteration 600 loss: 1440.296630859375\n",
      "=======Eppoch 4 finished, loss:  1852.0350025034065\n",
      "=======Epoch 5 start\n",
      "-------Iteration 0 loss: 1830.946044921875\n",
      "-------Iteration 200 loss: 2200.33056640625\n",
      "-------Iteration 400 loss: 2183.056396484375\n",
      "-------Iteration 600 loss: 1933.5999755859375\n",
      "=======Eppoch 5 finished, loss:  1845.659714056726\n",
      "=======Epoch 6 start\n",
      "-------Iteration 0 loss: 1773.0050048828125\n",
      "-------Iteration 200 loss: 1627.6085205078125\n",
      "-------Iteration 400 loss: 1868.49951171875\n",
      "-------Iteration 600 loss: 2194.052978515625\n",
      "=======Eppoch 6 finished, loss:  1828.1502839978398\n",
      "=======Epoch 7 start\n",
      "-------Iteration 0 loss: 1204.0631103515625\n",
      "-------Iteration 200 loss: 1324.22119140625\n",
      "-------Iteration 400 loss: 1713.3082275390625\n",
      "-------Iteration 600 loss: 2241.64111328125\n",
      "=======Eppoch 7 finished, loss:  1815.2488589398743\n",
      "=======Epoch 8 start\n",
      "-------Iteration 0 loss: 1577.7335205078125\n",
      "-------Iteration 200 loss: 2207.486328125\n",
      "-------Iteration 400 loss: 1823.9952392578125\n",
      "-------Iteration 600 loss: 1326.890380859375\n",
      "=======Eppoch 8 finished, loss:  1766.4747857755203\n",
      "=======Epoch 9 start\n",
      "-------Iteration 0 loss: 1966.9605712890625\n",
      "-------Iteration 200 loss: 2340.214111328125\n",
      "-------Iteration 400 loss: 1739.5059814453125\n",
      "-------Iteration 600 loss: 1820.4893798828125\n",
      "=======Eppoch 9 finished, loss:  1784.730810003717\n",
      "=======Epoch 10 start\n",
      "-------Iteration 0 loss: 1635.07568359375\n",
      "-------Iteration 200 loss: 1806.6793212890625\n",
      "-------Iteration 400 loss: 2248.15966796875\n",
      "-------Iteration 600 loss: 878.9915161132812\n",
      "=======Eppoch 10 finished, loss:  1779.5931494379026\n",
      "=======Epoch 11 start\n",
      "-------Iteration 0 loss: 2072.900146484375\n",
      "-------Iteration 200 loss: 1954.9324951171875\n",
      "-------Iteration 400 loss: 1689.823974609375\n",
      "-------Iteration 600 loss: 1435.943359375\n",
      "=======Eppoch 11 finished, loss:  1750.725134194806\n",
      "=======Epoch 12 start\n",
      "-------Iteration 0 loss: 1400.4281005859375\n",
      "-------Iteration 200 loss: 1657.20947265625\n",
      "-------Iteration 400 loss: 1966.2794189453125\n",
      "-------Iteration 600 loss: 2110.09716796875\n",
      "=======Eppoch 12 finished, loss:  1750.7375263490414\n",
      "=======Epoch 13 start\n",
      "-------Iteration 0 loss: 2218.3486328125\n",
      "-------Iteration 200 loss: 1908.8446044921875\n",
      "-------Iteration 400 loss: 1910.913818359375\n",
      "-------Iteration 600 loss: 940.096435546875\n",
      "=======Eppoch 13 finished, loss:  1753.9832859873102\n",
      "=======Epoch 14 start\n",
      "-------Iteration 0 loss: 1772.9129638671875\n",
      "-------Iteration 200 loss: 1295.57763671875\n",
      "-------Iteration 400 loss: 1471.1865234375\n",
      "-------Iteration 600 loss: 1496.9886474609375\n",
      "=======Eppoch 14 finished, loss:  1759.3227168810022\n",
      "=======Epoch 15 start\n",
      "-------Iteration 0 loss: 1277.7847900390625\n",
      "-------Iteration 200 loss: 1649.73095703125\n",
      "-------Iteration 400 loss: 1695.779296875\n",
      "-------Iteration 600 loss: 1383.7000732421875\n",
      "=======Eppoch 15 finished, loss:  1739.9774428834216\n",
      "=======Epoch 16 start\n",
      "-------Iteration 0 loss: 1038.7939453125\n",
      "-------Iteration 200 loss: 2030.0662841796875\n",
      "-------Iteration 400 loss: 1792.7117919921875\n",
      "-------Iteration 600 loss: 1495.6983642578125\n",
      "=======Eppoch 16 finished, loss:  1755.9557280206805\n",
      "=======Epoch 17 start\n",
      "-------Iteration 0 loss: 1959.4820556640625\n",
      "-------Iteration 200 loss: 2486.6962890625\n",
      "-------Iteration 400 loss: 2632.757568359375\n",
      "-------Iteration 600 loss: 2044.775146484375\n",
      "=======Eppoch 17 finished, loss:  1716.461557294737\n",
      "=======Epoch 18 start\n",
      "-------Iteration 0 loss: 2040.0616455078125\n",
      "-------Iteration 200 loss: 1341.4822998046875\n",
      "-------Iteration 400 loss: 1735.932373046875\n",
      "-------Iteration 600 loss: 1883.187255859375\n",
      "=======Eppoch 18 finished, loss:  1727.9289854589856\n",
      "=======Epoch 19 start\n",
      "-------Iteration 0 loss: 2340.363525390625\n",
      "-------Iteration 200 loss: 2048.7236328125\n",
      "-------Iteration 400 loss: 1186.1473388671875\n",
      "-------Iteration 600 loss: 2192.431396484375\n",
      "=======Eppoch 19 finished, loss:  1724.0293113499833\n",
      "=======Epoch 20 start\n",
      "-------Iteration 0 loss: 1571.837158203125\n",
      "-------Iteration 200 loss: 1432.7225341796875\n",
      "-------Iteration 400 loss: 1963.833984375\n",
      "-------Iteration 600 loss: 2064.856689453125\n",
      "=======Eppoch 20 finished, loss:  1741.8227912043349\n",
      "=======Epoch 21 start\n",
      "-------Iteration 0 loss: 1801.3934326171875\n",
      "-------Iteration 200 loss: 1931.3868408203125\n",
      "-------Iteration 400 loss: 1552.160888671875\n",
      "-------Iteration 600 loss: 1652.7115478515625\n",
      "=======Eppoch 21 finished, loss:  1727.727457026226\n",
      "=======Epoch 22 start\n",
      "-------Iteration 0 loss: 805.705078125\n",
      "-------Iteration 200 loss: 2192.98876953125\n"
     ]
    }
   ],
   "source": [
    "for epoch in epochs:\n",
    "   logging.info('Running epoch = %d' % epoch)\n",
    "\n",
    "   # Learning rate varies with epoch\n",
    "   for group in optimizer.param_groups:\n",
    "       if(epoch >= 4 & epoch < 80):\n",
    "           group['lr'] = 1e-4\n",
    "       if(epoch>=80 & epoch<160):\n",
    "           group['lr'] = 1e-5\n",
    "       if(epoch>=160):\n",
    "           group['lr'] = 1e-6\n",
    "\n",
    "   for batch_idx, (rgb_map, target) in enumerate(data_loader): \n",
    "          if(batch_idx == num_iters):\n",
    "              break\n",
    "\n",
    "          logging.info(\"Running batch_idx = %d\" % batch_idx)\n",
    "         \n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          rgb_map = rgb_map.view(rgb_map.data.size(0),rgb_map.data.size(3),rgb_map.data.size(1),rgb_map.data.size(2))\n",
    "          output = model(rgb_map.float().cuda())\n",
    "\n",
    "          loss = region_loss(output,target, loss_history, epoch, batch_idx)\n",
    "          loss.backward()\n",
    "\n",
    "          optimizer.step()\n",
    "\n",
    "   # Average the loss for all batches in the same epoch and log the loss\t\n",
    "   loss_epoch = loss_history[epoch, :, :].mean(axis = 0)\n",
    "   logging.info(\"Epoch loss = %s\" % loss_epoch)\n",
    "   print('=======Eppoch {} finished, loss:  {}'.format(epoch, sum(loss_epoch))) \n",
    "\n",
    "   # Add tensorboard looging to monitor losses in real time\n",
    "   tensorboard_info = dict(zip(['x', 'y', 'w', 'l', 'conf', 'cls', 'euler'], loss_epoch))\n",
    "   tensorboard = Logger('./logs')\n",
    "   tensorboard.scalar_summary(tensorboard_info, epoch)\n",
    "   \n",
    "   # Save model and loss every 50 epochs\n",
    "   if (epoch % 2 == 0):\n",
    "       logging.info(\"Saving model at epoch = %d\" % epoch)\n",
    "       torch.save(model, \"model/ComplexYOLO_epoch\" + str(epoch))\n",
    "       \n",
    "       logging.info(\"Saving all losses at epoch = %d\" % epoch)\n",
    "       np.save(\"loss/complexYOLO_epoch\" + str(epoch), loss_history)\n",
    "\n",
    "# Save model and loss at the very end\n",
    "logging.info(\"Saving model at the last epoch = %d!\" % epoch)\n",
    "torch.save(model, \"model/ComplexYOLO_epoch\" + str(epoch))\n",
    "\n",
    "logging.info(\"Saving all losses at the last epoch = %d!\" % epoch)\n",
    "np.save(\"loss/complexYOLO_epoch\" + str(epoch), loss_history)\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date_str = str(datetime.date.today())\n",
    "#logging_file = 'training_log_' + date_str + '.log'\n",
    "#logging.basicConfig(filename = logging_file, level=logging.DEBUG, format = '%(asctime)s %(message)s')\n",
    "\n",
    "batch_size = 12\n",
    "\n",
    "# Remove old loggings in the tensorboard folder \n",
    "\n",
    "\n",
    "# dataset\n",
    "dataset=KittiDataset(root = '/home/ubuntu/KITTI', set = 'train')\n",
    "data_loader = data.DataLoader(dataset, batch_size, shuffle = True, pin_memory = False)\n",
    "\n",
    "#model = ComplexYOLO()\n",
    "model = torch.load(\"model/ComplexYOLO_epoch26\")\n",
    "model.cuda()\n",
    "\n",
    "# define optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr = 5e-5 ,momentum = 0.9 , weight_decay = 0.0005)\n",
    "\n",
    "# define the number of epochs\n",
    "epochs = range(27, 41)\n",
    "\n",
    "# Define the loss function\n",
    "region_loss = RegionLoss(num_classes = 8, num_anchors = 5)\n",
    "num_iters = int(len(data_loader.dataset) / batch_size)\n",
    "#loss_history = np.zeros((len(epochs), num_iters, 8))\n",
    "loss_history = np.zeros((1000, num_iters, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in epochs:\n",
    "   logging.info('Running epoch = %d' % epoch)\n",
    "\n",
    "   # Learning rate varies with epoch\n",
    "   for group in optimizer.param_groups:\n",
    "       if(epoch >= 4 & epoch < 80):\n",
    "           group['lr'] = 1e-4\n",
    "       if(epoch>=80 & epoch<160):\n",
    "           group['lr'] = 1e-5\n",
    "       if(epoch>=160):\n",
    "           group['lr'] = 1e-6\n",
    "\n",
    "   for batch_idx, (rgb_map, target) in enumerate(data_loader): \n",
    "          if(batch_idx == num_iters):\n",
    "              break\n",
    "\n",
    "          #logging.info(\"Running batch_idx = %d\" % batch_idx)\n",
    "         \n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          rgb_map = rgb_map.view(rgb_map.data.size(0),rgb_map.data.size(3),rgb_map.data.size(1),rgb_map.data.size(2))\n",
    "          output = model(rgb_map.float().cuda())\n",
    "\n",
    "          loss = region_loss(output,target, loss_history, epoch, batch_idx)\n",
    "          loss.backward()\n",
    "\n",
    "          optimizer.step()\n",
    "\n",
    "   # Average the loss for all batches in the same epoch and log the loss\t\n",
    "   loss_epoch = loss_history[epoch, :, :].mean(axis = 0)\n",
    "   #logging.info(\"Epoch loss = %s\" % loss_epoch)\n",
    "   print('=======Eppoch {} finished, loss:  {}'.format(epoch, sum(loss_epoch))) \n",
    "\n",
    "   # Add tensorboard looging to monitor losses in real time\n",
    "   #tensorboard_info = dict(zip(['x', 'y', 'w', 'l', 'conf', 'cls', 'euler'], loss_epoch))\n",
    "   #tensorboard = Logger('./logs')\n",
    "   #tensorboard.scalar_summary(tensorboard_info, epoch)\n",
    "   \n",
    "   # Save model and loss every 50 epochs\n",
    "   if (epoch % 2 == 0):\n",
    "       #logging.info(\"Saving model at epoch = %d\" % epoch)\n",
    "       torch.save(model, \"model/ComplexYOLO_epoch\" + str(epoch))\n",
    "       \n",
    "       #logging.info(\"Saving all losses at epoch = %d\" % epoch)\n",
    "       np.save(\"loss/complexYOLO_epoch\" + str(epoch), loss_history)\n",
    "\n",
    "# Save model and loss at the very end\n",
    "#logging.info(\"Saving model at the last epoch = %d!\" % epoch)\n",
    "torch.save(model, \"model/ComplexYOLO_epoch\" + str(epoch))\n",
    "\n",
    "#logging.info(\"Saving all losses at the last epoch = %d!\" % epoch)\n",
    "np.save(\"loss/complexYOLO_epoch\" + str(epoch), loss_history)\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date_str = str(datetime.date.today())\n",
    "#logging_file = 'training_log_' + date_str + '.log'\n",
    "#logging.basicConfig(filename = logging_file, level=logging.DEBUG, format = '%(asctime)s %(message)s')\n",
    "\n",
    "batch_size = 12\n",
    "\n",
    "# Remove old loggings in the tensorboard folder \n",
    "\n",
    "\n",
    "# dataset\n",
    "dataset=KittiDataset(root = '/home/ubuntu/KITTI', set = 'train')\n",
    "data_loader = data.DataLoader(dataset, batch_size, shuffle = True, pin_memory = False)\n",
    "\n",
    "#model = ComplexYOLO()\n",
    "model = torch.load(\"model/ComplexYOLO_epoch40\")\n",
    "model.cuda()\n",
    "\n",
    "# define optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr = 5e-5 ,momentum = 0.9 , weight_decay = 0.0005)\n",
    "\n",
    "# define the number of epochs\n",
    "epochs = range(41, 51)\n",
    "\n",
    "# Define the loss function\n",
    "region_loss = RegionLoss(num_classes = 8, num_anchors = 5)\n",
    "num_iters = int(len(data_loader.dataset) / batch_size)\n",
    "#loss_history = np.zeros((len(epochs), num_iters, 8))\n",
    "loss_history = np.zeros((1000, num_iters, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Epoch 41 start\n",
      "-------Iteration 0 loss: 1315.03601074\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f005cb083a44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m            \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrgb_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m           \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m               \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/complex_yolo_3d/kitti.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlidar_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremovePoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakeBVFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbc\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# (512, 1024, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/complex_yolo_3d/utils.pyc\u001b[0m in \u001b[0;36mremovePoints\u001b[0;34m(PointCloud, BoundaryCond)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Remove the point out of range x,y,z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPointCloud\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mPointCloud\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mmaxX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mPointCloud\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mPointCloud\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mmaxY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mPointCloud\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminZ\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mPointCloud\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mmaxZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mPointCloud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPointCloud\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mPointCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in epochs:\n",
    "   logging.info('Running epoch = %d' % epoch)\n",
    "\n",
    "   # Learning rate varies with epoch\n",
    "   for group in optimizer.param_groups:\n",
    "       if(epoch >= 4 & epoch < 40):\n",
    "           group['lr'] = 1e-4\n",
    "       if(epoch>=40 & epoch<160):\n",
    "           group['lr'] = 1e-5\n",
    "       if(epoch>=160):\n",
    "           group['lr'] = 1e-6\n",
    "\n",
    "   for batch_idx, (rgb_map, target) in enumerate(data_loader): \n",
    "          if(batch_idx == num_iters):\n",
    "              break\n",
    "\n",
    "          #logging.info(\"Running batch_idx = %d\" % batch_idx)\n",
    "         \n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          rgb_map = rgb_map.view(rgb_map.data.size(0),rgb_map.data.size(3),rgb_map.data.size(1),rgb_map.data.size(2))\n",
    "          output = model(rgb_map.float().cuda())\n",
    "\n",
    "          loss = region_loss(output,target, loss_history, epoch, batch_idx)\n",
    "          loss.backward()\n",
    "\n",
    "          optimizer.step()\n",
    "\n",
    "   # Average the loss for all batches in the same epoch and log the loss\t\n",
    "   loss_epoch = loss_history[epoch, :, :].mean(axis = 0)\n",
    "   #logging.info(\"Epoch loss = %s\" % loss_epoch)\n",
    "   print('=======Eppoch {} finished, loss:  {}'.format(epoch, sum(loss_epoch))) \n",
    "\n",
    "   # Add tensorboard looging to monitor losses in real time\n",
    "   #tensorboard_info = dict(zip(['x', 'y', 'w', 'l', 'conf', 'cls', 'euler'], loss_epoch))\n",
    "   #tensorboard = Logger('./logs')\n",
    "   #tensorboard.scalar_summary(tensorboard_info, epoch)\n",
    "   \n",
    "   # Save model and loss every 50 epochs\n",
    "   if (epoch % 2 == 0):\n",
    "       #logging.info(\"Saving model at epoch = %d\" % epoch)\n",
    "       torch.save(model, \"model/ComplexYOLO_epoch\" + str(epoch))\n",
    "       \n",
    "       #logging.info(\"Saving all losses at epoch = %d\" % epoch)\n",
    "       np.save(\"loss/complexYOLO_epoch\" + str(epoch), loss_history)\n",
    "\n",
    "# Save model and loss at the very end\n",
    "#logging.info(\"Saving model at the last epoch = %d!\" % epoch)\n",
    "torch.save(model, \"model/ComplexYOLO_epoch\" + str(epoch))\n",
    "\n",
    "#logging.info(\"Saving all losses at the last epoch = %d!\" % epoch)\n",
    "np.save(\"loss/complexYOLO_epoch\" + str(epoch), loss_history)\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Epoch 45 start\n",
      "-------Iteration 0 loss: 1704.62487793\n",
      "-------Iteration 200 loss: 1613.78295898\n",
      "-------Iteration 400 loss: 2044.78723145\n",
      "-------Iteration 600 loss: 1292.21057129\n",
      "=======Eppoch 45 finished, loss:  1692.78230136\n",
      "=======Epoch 46 start\n",
      "-------Iteration 0 loss: 1780.33459473\n",
      "-------Iteration 200 loss: 884.127624512\n",
      "-------Iteration 400 loss: 1148.31274414\n",
      "-------Iteration 600 loss: 1621.02978516\n",
      "=======Eppoch 46 finished, loss:  1722.00764467\n",
      "=======Epoch 47 start\n",
      "-------Iteration 0 loss: 1105.15649414\n",
      "-------Iteration 200 loss: 869.00012207\n",
      "-------Iteration 400 loss: 1725.48144531\n",
      "-------Iteration 600 loss: 2049.80639648\n",
      "=======Eppoch 47 finished, loss:  1711.64875156\n",
      "=======Epoch 48 start\n",
      "-------Iteration 0 loss: 1282.03515625\n",
      "-------Iteration 200 loss: 2706.73754883\n",
      "-------Iteration 400 loss: 1939.37426758\n",
      "-------Iteration 600 loss: 2026.06384277\n",
      "=======Eppoch 48 finished, loss:  1702.07132935\n",
      "=======Epoch 49 start\n",
      "-------Iteration 0 loss: 2126.57128906\n",
      "-------Iteration 200 loss: 1483.87878418\n",
      "-------Iteration 400 loss: 2057.51513672\n",
      "-------Iteration 600 loss: 1289.71704102\n",
      "=======Eppoch 49 finished, loss:  1729.16520056\n",
      "=======Epoch 50 start\n",
      "-------Iteration 0 loss: 1475.44042969\n",
      "-------Iteration 200 loss: 1813.41882324\n",
      "-------Iteration 400 loss: 1593.06555176\n",
      "-------Iteration 600 loss: 1445.4152832\n",
      "=======Eppoch 50 finished, loss:  1695.04452983\n",
      "=======Epoch 51 start\n",
      "-------Iteration 0 loss: 1904.5802002\n",
      "-------Iteration 200 loss: 1747.71350098\n",
      "-------Iteration 400 loss: 1749.88134766\n",
      "-------Iteration 600 loss: 1377.44873047\n",
      "=======Eppoch 51 finished, loss:  1689.93063029\n",
      "=======Epoch 52 start\n",
      "-------Iteration 0 loss: 2095.02661133\n",
      "-------Iteration 200 loss: 1879.35864258\n",
      "-------Iteration 400 loss: 1430.25634766\n",
      "-------Iteration 600 loss: 1235.34008789\n",
      "=======Eppoch 52 finished, loss:  1699.46407922\n",
      "=======Epoch 53 start\n",
      "-------Iteration 0 loss: 1767.50854492\n",
      "-------Iteration 200 loss: 1876.71374512\n",
      "-------Iteration 400 loss: 2391.05810547\n",
      "-------Iteration 600 loss: 2340.33935547\n",
      "=======Eppoch 53 finished, loss:  1753.82921561\n",
      "=======Epoch 54 start\n",
      "-------Iteration 0 loss: 1131.11291504\n",
      "-------Iteration 200 loss: 1710.57580566\n",
      "-------Iteration 400 loss: 1905.77856445\n",
      "-------Iteration 600 loss: 1790.76501465\n",
      "=======Eppoch 54 finished, loss:  1719.31748514\n",
      "=======Epoch 55 start\n",
      "-------Iteration 0 loss: 1821.70788574\n",
      "-------Iteration 200 loss: 1308.76086426\n",
      "-------Iteration 400 loss: 1222.88659668\n",
      "-------Iteration 600 loss: 1466.83007812\n",
      "=======Eppoch 55 finished, loss:  1724.14286597\n",
      "=======Epoch 56 start\n",
      "-------Iteration 0 loss: 1342.46960449\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4a2df9435559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#            group['lr'] = 1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrgb_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m           \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m               \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/complex_yolo_3d/kitti.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremovePoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakeBVFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbc\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# (512, 1024, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/complex_yolo_3d/utils.pyc\u001b[0m in \u001b[0;36mmakeBVFeature\u001b[0;34m(PointCloud_, BoundaryCond, Discretization)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m     85\u001b[0m     \u001b[0mRGB_Map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHeight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mWidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mRGB_Map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdensityMap\u001b[0m      \u001b[0;31m# r_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mRGB_Map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheightMap\u001b[0m       \u001b[0;31m# g_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mRGB_Map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintensityMap\u001b[0m    \u001b[0;31m# b_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#date_str = str(datetime.date.today())\n",
    "#logging_file = 'training_log_' + date_str + '.log'\n",
    "#logging.basicConfig(filename = logging_file, level=logging.DEBUG, format = '%(asctime)s %(message)s')\n",
    "\n",
    "batch_size = 12\n",
    "\n",
    "# Remove old loggings in the tensorboard folder \n",
    "\n",
    "\n",
    "# dataset\n",
    "dataset=KittiDataset(root = '/home/ubuntu/KITTI', set = 'train')\n",
    "data_loader = data.DataLoader(dataset, batch_size, shuffle = True, pin_memory = False)\n",
    "\n",
    "#model = ComplexYOLO()\n",
    "model = torch.load(\"model/ComplexYOLO_epoch44\")\n",
    "model.cuda()\n",
    "\n",
    "# define optimizer\n",
    "#optimizer = optim.SGD(model.parameters(), lr = 1e-5 ,momentum = 0.9 , weight_decay = 0.0005)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-5)\n",
    "# define the number of epochs\n",
    "epochs = range(45, 65)\n",
    "\n",
    "# Define the loss function\n",
    "region_loss = RegionLoss(num_classes = 8, num_anchors = 5)\n",
    "num_iters = int(len(data_loader.dataset) / batch_size)\n",
    "#loss_history = np.zeros((len(epochs), num_iters, 8))\n",
    "loss_history = np.zeros((1000, num_iters, 8))\n",
    "\n",
    "\n",
    "for epoch in epochs:\n",
    "   logging.info('Running epoch = %d' % epoch)\n",
    "\n",
    "   # Learning rate varies with epoch\n",
    "#    for group in optimizer.param_groups:\n",
    "#        if(epoch >= 4 & epoch < 40):\n",
    "#            group['lr'] = 1e-4\n",
    "#        if(epoch>=40 & epoch<160):\n",
    "#            group['lr'] = 1e-5\n",
    "#        if(epoch>=160):\n",
    "#            group['lr'] = 1e-6\n",
    "\n",
    "   for batch_idx, (rgb_map, target) in enumerate(data_loader): \n",
    "          if(batch_idx == num_iters):\n",
    "              break\n",
    "or epoch in epochs:\n",
    "logging.info('Running epoch = %d' % epoch)\n",
    "\n",
    "Learning rate varies with epoch\n",
    "for group in optimizer.param_groups: if(epoch >= 4 & epoch < 80): group['lr'] = 1e-4 if(epoch>=80 & epoch<160): group['lr'] = 1e-5 if(epoch>=160): group['lr'] = 1e-6\n",
    "\n",
    "for batch_idx, (rgb_map, target) in enumerate(data_loader): if(batch_idx == num_iters): break\n",
    "\n",
    "      #logging.info(\"Running batch_idx = %d\" % batch_idx)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      rgb_map = rgb_map.view(rgb_map.data.size(0),rgb_map.data.size(3),rgb_map.data.size(1),rgb_map.data.size(2))\n",
    "      output = model(rgb_map.float().cuda())\n",
    "\n",
    "      loss = region_loss(output,target, loss_history, epoch, batch_idx)\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "Average the loss for all batches in the same epoch and log the loss\n",
    "loss_epoch = loss_history[epoch, :, :].mean(axis = 0)\n",
    "\n",
    "#logging.info(\"Epoch loss = %s\" % loss_epoch) print('=======Eppoch {} finished, loss: {}'.format(epoch, sum(loss_epoch)))\n",
    "\n",
    "Add tensorboard looging to monitor losses in real time\n",
    "#tensorboard_info = dict(zip(['x', 'y', 'w', 'l', 'conf', 'cls', 'euler'], loss_epoch))\n",
    "\n",
    "#tensorboard = Logger('./logs')\n",
    "\n",
    "#tensorboard.scalar_summary(tensorboard_info, epoch)\n",
    "\n",
    "Save model and loss every 50 epochs\n",
    "if (epoch % 2 == 0):\n",
    "\n",
    "   #logging.info(\"Saving model at epoch = %d\" % epoch)\n",
    "   torch.save(model, \"model/ComplexYOLO_epoch\" + str(epoch))\n",
    "\n",
    "   #logging.info(\"Saving all losses at epoch = %d\" % epoch)\n",
    "   np.save(\"loss/complexYOLO_epoch\" + str(epoch), loss_history)\n",
    "Save model and loss at the very endÂ¶\n",
    "          #logging.info(\"Running batch_idx = %d\" % batch_idx)\n",
    "         \n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          rgb_map = rgb_map.view(rgb_map.data.size(0),rgb_map.data.size(3),rgb_map.data.size(1),rgb_map.data.size(2))\n",
    "          output = model(rgb_map.float().cuda())\n",
    "\n",
    "          loss = region_loss(output,target, loss_history, epoch, batch_idx)\n",
    "          loss.backward()\n",
    "\n",
    "          optimizer.step()\n",
    "\n",
    "   # Average the loss for all batches in the same epoch and log the loss\t\n",
    "   loss_epoch = loss_history[epoch, :, :].mean(axis = 0)\n",
    "   #logging.info(\"Epoch loss = %s\" % loss_epoch)\n",
    "   print('=======Eppoch {} finished, loss:  {}'.format(epoch, sum(loss_epoch))) \n",
    "\n",
    "   # Add tensorboard looging to monitor losses in real time\n",
    "   #tensorboard_info = dict(zip(['x', 'y', 'w', 'l', 'conf', 'cls', 'euler'], loss_epoch))\n",
    "   #tensorboard = Logger('./logs')\n",
    "   #tensorboard.scalar_summary(tensorboard_info, epoch)\n",
    "   \n",
    "   # Save model and loss every 50 epochs\n",
    "   if (epoch % 2 == 0):\n",
    "       #logging.info(\"Saving model at epoch = %d\" % epoch)\n",
    "       torch.save(model, \"model/ComplexYOLO_epoch\" + str(epoch))\n",
    "       \n",
    "       #logging.info(\"Saving all losses at epoch = %d\" % epoch)\n",
    "       np.save(\"loss/complexYOLO_epoch\" + str(epoch), loss_history)\n",
    "\n",
    "# Save model and loss at the very end\n",
    "#logging.info(\"Saving model at the last epoch = %d!\" % epoch)\n",
    "torch.save(model, \"model/ComplexYOLO_epoch\" + str(epoch))\n",
    "\n",
    "#logging.info(\"Saving all losses at the last epoch = %d!\" % epoch)\n",
    "np.save(\"loss/complexYOLO_epoch\" + str(epoch), loss_history)\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "region_loss.py:216: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = loss_x + loss_y + loss_w + loss_l + loss_conf + loss_cls + loss_Euler + torch.tensor(loss_iou).cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Epoch 55 start\n",
      "-------Iteration 0 loss: 1502.82568359\n",
      "-------Iteration 200 loss: 1530.10302734\n",
      "-------Iteration 400 loss: 1686.76025391\n",
      "-------Iteration 600 loss: 1676.02392578\n",
      "=======Eppoch 55 finished, loss:  1716.91826859\n",
      "=======Epoch 56 start\n",
      "-------Iteration 0 loss: 1173.19689941\n",
      "-------Iteration 200 loss: 1984.96630859\n",
      "-------Iteration 400 loss: 1787.05480957\n",
      "-------Iteration 600 loss: 1631.59265137\n",
      "=======Eppoch 56 finished, loss:  1747.74293974\n"
     ]
    }
   ],
   "source": [
    "#date_str = str(datetime.date.today())\n",
    "#logging_file = 'training_log_' + date_str + '.log'\n",
    "#logging.basicConfig(filename = logging_file, level=logging.DEBUG, format = '%(asctime)s %(message)s')\n",
    "\n",
    "batch_size = 12\n",
    "\n",
    "# Remove old loggings in the tensorboard folder \n",
    "\n",
    "\n",
    "# dataset\n",
    "dataset=KittiDataset(root = '/home/ubuntu/KITTI', set = 'train')\n",
    "data_loader = data.DataLoader(dataset, batch_size, shuffle = True, pin_memory = False)\n",
    "\n",
    "#model = ComplexYOLO()\n",
    "model = torch.load(\"model/ComplexYOLO_epoch54\")\n",
    "model.cuda()\n",
    "\n",
    "# define optimizer\n",
    "#optimizer = optim.SGD(model.parameters(), lr = 1e-5 ,momentum = 0.9 , weight_decay = 0.0005)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-5)\n",
    "# define the number of epochs\n",
    "epochs = range(55, 57)\n",
    "\n",
    "# Define the loss function\n",
    "region_loss = RegionLoss(num_classes = 8, num_anchors = 5)\n",
    "num_iters = int(len(data_loader.dataset) / batch_size)\n",
    "#loss_history = np.zeros((len(epochs), num_iters, 8))\n",
    "loss_history = np.zeros((1000, num_iters, ))\n",
    "\n",
    "\n",
    "for epoch in epochs:\n",
    "   logging.info('Running epoch = %d' % epoch)\n",
    "\n",
    "   # Learning rate varies with epoch\n",
    "#    for group in optimizer.param_groups:\n",
    "#        if(epoch >= 4 & epoch < 40):\n",
    "#            group['lr'] = 1e-4\n",
    "#        if(epoch>=40 & epoch<160):\n",
    "#            group['lr'] = 1e-5\n",
    "#        if(epoch>=160):\n",
    "#            group['lr'] = 1e-6\n",
    "\n",
    "   for batch_idx, (rgb_map, target) in enumerate(data_loader): \n",
    "          if(batch_idx == num_iters):\n",
    "              break\n",
    "\n",
    "          #logging.info(\"Running batch_idx = %d\" % batch_idx)\n",
    "         \n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          rgb_map = rgb_map.view(rgb_map.data.size(0),rgb_map.data.size(3),rgb_map.data.size(1),rgb_map.data.size(2))\n",
    "          output = model(rgb_map.float().cuda())\n",
    "\n",
    "          loss = region_loss(output,target, loss_history, epoch, batch_idx)\n",
    "          loss.backward()\n",
    "\n",
    "          optimizer.step()\n",
    "\n",
    "   # Average the loss for all batches in the same epoch and log the loss\t\n",
    "   loss_epoch = loss_history[epoch, :, :].mean(axis = 0)\n",
    "   #logging.info(\"Epoch loss = %s\" % loss_epoch)\n",
    "   print('=======Eppoch {} finished, loss:  {}'.format(epoch, sum(loss_epoch))) \n",
    "\n",
    "   # Add tensorboard looging to monitor losses in real time\n",
    "   #tensorboard_info = dict(zip(['x', 'y', 'w', 'l', 'conf', 'cls', 'euler'], loss_epoch))\n",
    "   #tensorboard = Logger('./logs')\n",
    "   #tensorboard.scalar_summary(tensorboard_info, epoch)\n",
    "   \n",
    "   # Save model and loss every 50 epochs\n",
    "   if (epoch % 2 == 0):\n",
    "       #logging.info(\"Saving model at epoch = %d\" % epoch)\n",
    "       torch.save(model, \"model/ComplexYOLO_epoch\" + str(epoch))\n",
    "       \n",
    "       #logging.info(\"Saving all losses at epoch = %d\" % epoch)\n",
    "       np.save(\"loss/complexYOLO_epoch\" + str(epoch), loss_history)\n",
    "\n",
    "# Save model and loss at the very end\n",
    "#logging.info(\"Saving model at the last epoch = %d!\" % epoch)\n",
    "torch.save(model, \"model/ComplexYOLO_epoch\" + str(epoch))\n",
    "\n",
    "#logging.info(\"Saving all losses at the last epoch = %d!\" % epoch)\n",
    "np.save(\"loss/complexYOLO_epoch\" + str(epoch), loss_history)\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
